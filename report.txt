Assignment 4: Heap Data Structures: Implementation, Analysis, and Applications

Heapsort Implementation and Analysis

Analysis of Implementation
    -> The Heapsort algorithm is a comparison-based sorting technique built on the binary heap data structure. It operates in two main phases: (1) building a max heap from the input array, and (2) repeatedly extracting the largest element from the heap and placing it at the end of the array.
    Time Complexity Analysis
    1. Heap Construction: Building a max heap from an unsorted array takes O(n) time because the heapify operation is applied to all non-leaf nodes, and the work done decreases exponentially at each level of the heap.
    2. Sorting Phase: After the heap is built, each of the n elements is extracted once, and each extraction requires a heapify operation that takes O(log n) time (height of the heap). Thus, this phase costs O(n log n) time.
    
    Case-by-Case Analysis
    Case	                                         Description                                                               	Time Complexity
    Best Case	    Even if the array is already sorted, Heapsort still performs full heap construction and extraction.	          O(n log n)
    Average Case	For random input, each element requires heapify calls proportional to log n.	                              O(n log n)
    Worst Case	    Reverse-sorted input behaves the same as average, as Heapsort is insensitive to input order.                  O(n log n)

    Key Insight: Unlike Quicksort, whose performance heavily depends on the pivot selection, Heapsort consistently maintains O(n log n) performance across all cases, making it more predictable.
    Space Complexity
    1. Heapsort is an in-place sorting algorithm.
    2. It only requires O(1) auxiliary space as the sorting is performed within the original array using index manipulation.
    3. The only additional overhead comes from recursive calls in heapify, but this is limited to O(log n) due to the heap height.

    Additional Overheads
    1. The constant factors in Heapsort are typically higher than those of Quicksort because of frequent swap and heapify operations.
    2. Heapsort also lacks good cache performance since its access pattern jumps across the array, unlike Quicksort and MergeSort, which exhibit better locality of reference.

Comparison
  ->An empirical comparison was conducted between Heapsort, Quicksort, and MergeSort across different input distributions and input sizes (100 to 1000 elements). The results demonstrate the relative efficiency and practical behavior of each algorithm.

    3.1 Empirical Observations

    (a) Random Input
    1. Quicksort performed the fastest overall due to its efficient partitioning and cache-friendly access pattern.
    2. MergeSort followed closely, while Heapsort lagged slightly because of its larger constant factors.
    3. All three algorithms demonstrated the expected O(n log n) growth trend.

    (b) Sorted Input
    1. Quicksort maintained strong performance because of the randomized pivot selection in implementation.
    2. MergeSort showed stable times due to its consistent divide-and-conquer structure.
    3. Heapsort again displayed slightly higher times but remained consistent across input sizes.

    (c) Reverse-Sorted Input
    1. Similar to the sorted case, Heapsort was unaffected by input order, maintaining stable O(n log n) behavior.
    2. Quicksort’s randomized implementation prevented it from degrading to O(n²).
    3. MergeSort’s performance was consistent as always.

    (d) Nearly-Sorted Input
    1. Quicksort benefited significantly from nearly sorted data.
    2. MergeSort remained stable.
    3. Heapsort did not show improvement with sortedness, reaffirming that its performance is independent of input characteristics.

    3.2 Theoretical vs Empirical Analysis
    Algorithm	 Theoretical Complexity	                           Empirical Performance	                             Remarks
    Heapsort	 O(n log n) (all cases)	              Consistent but slightly slower due to swap overhead	   Predictable, stable, space-efficient
    Quicksort	 O(n log n) average, O(n²) worst	  Fastest in practice for all distributions	               Excellent cache performance
    MergeSort	 O(n log n) (all cases)	              Slightly slower than Quicksort	                       Stable, predictable, uses extra space O(n)

Conclusion
    Heapsort’s consistent O(n log n) time complexity makes it suitable for applications requiring predictable performance and low memory usage. However, for general-purpose sorting where average performance is prioritized over worst-case guarantees, Quicksort often remains the preferred choice due to its faster empirical behavior and better cache utilization.


Priority Queue Implementation and Applications
Part A: Priority Queue Implementation


1. Data Structure Selection

    For this implementation, a binary heap represented as a Python list was chosen. The rationale for this choice includes:
        1. Ease of Implementation: Arrays/lists allow easy calculation of parent and child indices using simple arithmetic (parent = (i-1)//2, left = 2*i+1, right = 2*i+2).
        2. Efficiency of Heap Operations: Binary heaps provide efficient insertion and extraction operations with O(log n) complexity, while supporting fast access to the top-priority element with O(1) time.
        3. Memory Efficiency: Using a list avoids the overhead of additional pointers required by tree-based structures.

    Task Representation
        A Task class was designed to encapsulate task-related information:
            task_id: Unique identifier for each task.
            priority: Determines the task’s urgency; higher numbers indicate higher priority.
            arrival_time: Timestamp when the task was added.
            deadline (optional): Deadline for task completion.
            description: Short description of the task.
            duration: Time required for execution.
    Comparison methods (__lt__, __gt__) were implemented to allow the heap to maintain order based on priority.

    Max-Heap vs Min-Heap
        A max-heap was chosen for this scheduler, as it allows execution of the highest priority task first, which aligns with typical real-world scheduling policies (urgent tasks should be executed before less critical tasks).

2. Core Operations and Complexity Analysis
    insert(task)
        Inserts a new task into the heap and maintains heap property via _heapify_up.
        Time Complexity: O(log n), because in the worst case the new element may traverse the height of the heap (~log n levels).

    extract_top()
        Removes and returns the highest-priority task and maintains heap property via _heapify_down.
        Time Complexity: O(log n), as the element swapped from the last position may move down to a leaf node.

    change_priority(task_id, new_priority)
        Updates the priority of an existing task and re-heapifies accordingly.
        Time Complexity: O(n) to locate the task + O(log n) for heapify = O(n) worst-case.
        This is acceptable for small to medium-sized heaps but can be optimized using a hash map for faster lookup.

    peek()
    Returns the top-priority task without removing it.
    Time Complexity: O(1).

    is_empty()
    checks if the heap is empty.
    Time Complexity: O(1).

3. Task Scheduler Application
    The TaskScheduler class demonstrates a real-world application of a priority queue:
        Tasks are added dynamically using add_task().
        The highest-priority task is executed next with execute_next().
        Queue state can be displayed with show_queue().
        Scheduling statistics (average waiting time, average turnaround time) are computed via get_statistics().

    Design Rationale:
        High-priority tasks are executed first, ensuring critical tasks are completed promptly.
        Task duration and arrival time are used to simulate real-time execution.
        Completed tasks are tracked to compute performance metrics.